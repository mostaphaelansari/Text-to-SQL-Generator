{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3160014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "619e05c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mosta\\anaconda3\\envs\\SQLtoTEXT\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d52588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the project root directory\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "data_path = os.path.join(project_root, 'text_to_sql_generator', 'data', 'processed', 'text2sql_clean.csv')\n",
    "cleaned_dataset = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50efa960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sql_prompt</th>\n",
       "      <th>sql</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the total volume of timber sold by eac...</td>\n",
       "      <td>SELECT salesperson_id, name, SUM(volume) as to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>List all the unique equipment types and their ...</td>\n",
       "      <td>SELECT equipment_type, SUM(maintenance_frequen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many marine species are found in the South...</td>\n",
       "      <td>SELECT COUNT(*) FROM marine_species WHERE loca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the total trade value and average pric...</td>\n",
       "      <td>SELECT trader_id, stock, SUM(price * quantity)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Find the energy efficiency upgrades with the h...</td>\n",
       "      <td>SELECT type, cost FROM (SELECT type, cost, ROW...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sql_prompt  \\\n",
       "0  What is the total volume of timber sold by eac...   \n",
       "1  List all the unique equipment types and their ...   \n",
       "2  How many marine species are found in the South...   \n",
       "3  What is the total trade value and average pric...   \n",
       "4  Find the energy efficiency upgrades with the h...   \n",
       "\n",
       "                                                 sql  \n",
       "0  SELECT salesperson_id, name, SUM(volume) as to...  \n",
       "1  SELECT equipment_type, SUM(maintenance_frequen...  \n",
       "2  SELECT COUNT(*) FROM marine_species WHERE loca...  \n",
       "3  SELECT trader_id, stock, SUM(price * quantity)...  \n",
       "4  SELECT type, cost FROM (SELECT type, cost, ROW...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1663380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cleaned_dataset)\n",
    "\n",
    "# Format input/output pairs\n",
    "PREFIX = \"translate to SQL: \"\n",
    "df[\"input_text\"] = PREFIX + df[\"sql_prompt\"]\n",
    "df[\"target_text\"] = df[\"sql\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd60ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Convert to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df[[\"input_text\", \"target_text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a270d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "model_checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def preprocess(example):\n",
    "    inputs = tokenizer(example[\"input_text\"], max_length=512, truncation=True, padding=\"max_length\")\n",
    "    targets = tokenizer(example[\"target_text\"], max_length=256, truncation=True, padding=\"max_length\")\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca7ecb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d9a17100494379b3da78e6f46abcfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6c2a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./t5-sql-finetuned\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=10,  # or less\n",
    "    max_steps=5000,       # override if needed\n",
    "    logging_dir=\"./logs\",\n",
    "    predict_with_generate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fa71b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21210982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mosta\\AppData\\Local\\Temp\\ipykernel_29908\\3049639269.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,              # Your model (T5, BART, etc.)\n",
    "    args=training_args,       # The training arguments you defined\n",
    "    train_dataset=tokenized_dataset,  # Your preprocessed training data\n",
    "    tokenizer=tokenizer,      # Tokenizer for your model\n",
    "    data_collator=data_collator,  # Handles batching and padding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 06:46, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.161500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.495100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.438800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.394400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.375300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.372800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.334500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.328900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.348500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5000, training_loss=0.4589886322021484, metrics={'train_runtime': 407.627, 'train_samples_per_second': 24.532, 'train_steps_per_second': 12.266, 'total_flos': 1353418014720000.0, 'train_loss': 0.4589886322021484, 'epoch': 0.1})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()  # âœ… This is the correct method to call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "851af125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT salesperson, COUNT(*) as total_volume FROM sales GROUP BY salesperson;\n"
     ]
    }
   ],
   "source": [
    "inference = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
    "\n",
    "output = inference(\n",
    "    \"translate to SQL: What is the total volume of timber sold by each salesperson?\",\n",
    "    max_length=100,\n",
    "    num_beams=5,\n",
    "    early_stopping=True\n",
    ")\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98a7508c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t5-sql-finetuned\\\\tokenizer_config.json',\n",
       " 't5-sql-finetuned\\\\special_tokens_map.json',\n",
       " 't5-sql-finetuned\\\\spiece.model',\n",
       " 't5-sql-finetuned\\\\added_tokens.json',\n",
       " 't5-sql-finetuned\\\\tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"t5-sql-finetuned\")\n",
    "tokenizer.save_pretrained(\"t5-sql-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ad51e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['checkpoint-1000', 'checkpoint-1500', 'checkpoint-15500', 'checkpoint-16000', 'checkpoint-2000', 'checkpoint-2500', 'checkpoint-3000', 'checkpoint-3500', 'checkpoint-4000', 'checkpoint-4500', 'checkpoint-500', 'checkpoint-5000', 'config.json', 'generation_config.json', 'model.safetensors', 'special_tokens_map.json', 'spiece.model', 'tokenizer.json', 'tokenizer_config.json']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"./t5-sql-finetuned\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a95fb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "t5\n"
     ]
    }
   ],
   "source": [
    "# Load the config file to see model details\n",
    "with open(\"./t5-sql-finetuned/config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "# This might give clues about the original model\n",
    "print(config.get(\"_name_or_path\", \"\"))\n",
    "print(config.get(\"model_type\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ead1d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Load your fine-tuned model\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"./t5-sql-finetuned\").to(\"cuda\")\n",
    "\n",
    "# Use the standard T5 tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"./t5-sql-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f76a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c672f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"lamini/spider_text_to_sql\")\n",
    "train_data = dataset[\"train\"]\n",
    "val_data = dataset[\"validation\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SQLtoTEXT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
